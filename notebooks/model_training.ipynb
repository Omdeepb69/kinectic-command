{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Kinectic Command: Gesture Recognition Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading and Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_synthetic_gesture_data(num_samples_per_gesture=100, num_features=42, num_gestures=4):\n",
        "    \"\"\"Generates synthetic gesture data (landmark features + labels).\"\"\"\n",
        "    np.random.seed(42)\n",
        "    gestures = ['fist', 'open_palm', 'pointing', 'ok']\n",
        "    if num_gestures > len(gestures):\n",
        "        raise ValueError(f\"Requested {num_gestures} gestures, but only {len(gestures)} are defined.\")\n",
        "    \n",
        "    selected_gestures = gestures[:num_gestures]\n",
        "    \n",
        "    X = []\n",
        "    y = []\n",
        "    \n",
        "    # Create distinct means for each gesture's features\n",
        "    means = [np.random.rand(num_features) * (i + 1) for i in range(num_gestures)]\n",
        "    \n",
        "    for i, gesture in enumerate(selected_gestures):\n",
        "        # Generate samples around the mean for this gesture\n",
        "        samples = means[i] + np.random.randn(num_samples_per_gesture, num_features) * 0.5 # Add noise\n",
        "        X.extend(samples)\n",
        "        y.extend([gesture] * num_samples_per_gesture)\n",
        "        \n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    \n",
        "    # Shuffle the data\n",
        "    indices = np.arange(len(y))\n",
        "    np.random.shuffle(indices)\n",
        "    X = X[indices]\n",
        "    y = y[indices]\n",
        "    \n",
        "    return X, y, selected_gestures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate or load data\n",
        "# In a real scenario, load pre-processed landmark data here\n",
        "X, y, gesture_labels = generate_synthetic_gesture_data(num_samples_per_gesture=200, num_features=42, num_gestures=4)\n",
        "\n",
        "print(f\"Generated data shape: X={X.shape}, y={y.shape}\")\n",
        "print(f\"Gesture labels: {gesture_labels}\")\n",
        "print(f\"Example features (first sample):\\n{X[0][:10]}...\") # Print first 10 features of first sample\n",
        "print(f\"Example label (first sample): {y[0]}\")\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"\\nTraining set size: {len(X_train)}\")\n",
        "print(f\"Test set size: {len(X_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"\\nData scaled using StandardScaler.\")\n",
        "print(f\"Example scaled features (first training sample):\\n{X_train_scaled[0][:10]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Model Definition and Training (Initial)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a simple SVM model\n",
        "initial_model = SVC(random_state=42)\n",
        "\n",
        "# Train the initial model\n",
        "initial_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Initial SVM model trained.\")\n",
        "\n",
        "# Evaluate the initial model (optional step here, full evaluation later)\n",
        "y_pred_initial = initial_model.predict(X_test_scaled)\n",
        "initial_accuracy = accuracy_score(y_test, y_pred_initial)\n",
        "print(f\"Initial model accuracy on test set: {initial_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the parameter grid for SVC\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100], \n",
        "    'gamma': [1, 0.1, 0.01, 0.001],\n",
        "    'kernel': ['rbf', 'linear']\n",
        "}\n",
        "\n",
        "print(\"Defined parameter grid for GridSearchCV:\")\n",
        "print(param_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform GridSearchCV\n",
        "# Use a smaller subset for faster tuning if needed, otherwise use full X_train_scaled\n",
        "grid_search = GridSearchCV(SVC(random_state=42), param_grid, refit=True, verbose=1, cv=5, n_jobs=-1)\n",
        "\n",
        "print(\"\\nStarting GridSearchCV...\")\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "print(\"GridSearchCV finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print best parameters and best score\n",
        "print(f\"\\nBest parameters found: {grid_search.best_params_}\")\n",
        "print(f\"Best cross-validation score (accuracy): {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# The best model is automatically refit on the entire training set\n",
        "best_model = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions on the test set using the best model\n",
        "y_pred_tuned = best_model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate final accuracy\n",
        "final_accuracy = accuracy_score(y_test, y_pred_tuned)\n",
        "print(f\"Tuned model accuracy on test set: {final_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "report = classification_report(y_test, y_pred_tuned, target_names=gesture_labels)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_tuned, labels=gesture_labels)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Results Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=gesture_labels, yticklabels=gesture_labels)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix for Gesture Recognition')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Save Model and Scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define file paths\n",
        "model_filename = 'gesture_model.joblib'\n",
        "scaler_filename = 'scaler.joblib'\n",
        "labels_filename = 'gesture_labels.joblib'\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(best_model, model_filename)\n",
        "print(f\"Trained model saved to {model_filename}\")\n",
        "\n",
        "# Save the scaler\n",
        "joblib.dump(scaler, scaler_filename)\n",
        "print(f\"Scaler saved to {scaler_filename}\")\n",
        "\n",
        "# Save the gesture labels\n",
        "joblib.dump(gesture_labels, labels_filename)\n",
        "print(f\"Gesture labels saved to {labels_filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### End of Notebook\n",
        "The trained model (`gesture_model.joblib`), the scaler (`scaler.joblib`), and the gesture labels (`gesture_labels.joblib`) are now saved and can be loaded by the main Kinectic Command application for real-time gesture recognition."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}